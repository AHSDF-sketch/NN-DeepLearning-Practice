# 第05章：线性模型 - 第5部分（含导航栏）
## 5.5 多分类策略与类别不平衡处理
### 核心内容1：多分类任务拆解法  
**<img width="1481" height="837" alt="image" src="https://github.com/user-attachments/assets/aacb7d43-ea06-4370-bf13-bbd192095caa" />**
###
| 策略类型       | 具体内容                                                                 | 优缺点分析                          |  文字解释                       |
|----------------|--------------------------------------------------------------------------|----------------------------------|-------------------------------------------------------|
| 一对一（OvO）  | 把N类拆成<br>$\frac{N(N-1)}{2}$个二分类任务（比如3类拆成“1v2”“1v3”“2v3”）；<br>每个任务训练1个分类器，预测时用“投票制”——得票最多的类别就是最终结果 | 优点：单个分类器只需要用2类样本训练，训练速度快；<br>缺点：分类器数量多（N=10时要45个），存储开销和测试时间成本高  | 拆解示意图：左栏是“3类样本（1、2、3）”，中栏是“3个分类器（1v2、1v3、2v3）”，右栏是“投票结果（比如1得2票，预测为1）”，旁注“分类器多，但训练快” |
| 一对多（OvR）  | 把N类拆成N个二分类任务（比如3类拆成“1v其他”“2v其他”“3v其他”）；<br>每个任务训练1个分类器，预测时选“正例概率最高”的类别作为最终结果 | 优点：分类器数量少（只有N个），存储和测试成本低；<br>缺点：单个分类器需要用全量样本训练，训练慢；存在样本不平衡（“其他类”样本多） | 拆解示意图：左栏是“3类样本”，中栏是“3个分类器（1v其他、2v其他、3v其他）”，右栏是“概率结果（比如2的正例概率0.8最高，预测为2）”，旁注“分类器少，但训练慢” |
| 性能对比       | 多数情况下，两种策略的预测精度相近；<br>样本均衡时，选OvO或OvR都可以；<br>样本不平衡时，OvO更优（避免“其他类”样本过多导致的偏差） | 实际应用中，要根据“训练时间”和“存储成本”权衡，优先按数据特点选择 | 性能对比图：横轴标注“样本量”，纵轴标注“测试精度”，OvO和OvR的曲线重合，旁注“多数场景下精度一样，按工程成本决定” |

### 核心内容2：类别不平衡处理（样本比例差异大）  
**<img width="1299" height="751" alt="image" src="https://github.com/user-attachments/assets/c0925426-bbe3-4a26-8f69-b45844ac6639" />**
| 处理方法       | 具体技术与逻辑                                                           | 适用场景                          | 优缺点分析                          |  文字解释                         |
|----------------|--------------------------------------------------------------------------|----------------------------------|----------------------------------|-------------------------------------------------------|
| 过采样         | 增加少数类样本数量，让类别比例平衡：<br>1. 简单复制：直接复制少数类样本（容易导致模型过拟合）；<br>2. SMOTE（合成少数类过采样技术）：在少数类样本的最近邻之间合成新样本（比如样本A和最近邻B之间，生成<br>$A + \alpha(B - A)$，$\alpha$是0到1之间的数） | 少数类样本少且信息重要的场景（比如医疗罕见病检测、金融欺诈识别） | 优点：不会丢失信息，能提高少数类的识别率；<br>缺点：简单复制易过拟合，SMOTE的计算成本高 | SMOTE示意图：左栏是“原始样本（少数类3个）”，右栏是“SMOTE后样本（少数类8个，含合成样本）”，旁注“合成新样本能减少过拟合风险” |
| 欠采样         | 减少多数类样本数量，让类别比例平衡：<br>1. 随机欠采样：随机删除多数类样本（容易丢失关键信息）；<br>2. NearMiss：删除与少数类样本距离远的多数类样本（保留相关样本，减少信息丢失）；<br>3. 聚类欠采样：对多数类做聚类，每个聚类选代表性样本（降低信息丢失，但计算复杂） | 多数类样本多且计算资源有限的场景（比如大规模数据集分类） | 优点：降低计算成本，避免模型对多数类过拟合；<br>缺点：随机欠采样容易丢失关键信息  | NearMiss示意图：左栏是“原始多数类（10个样本）”，右栏是“NearMiss后（5个样本，都靠近少数类）”，旁注“保留关键样本，减少信息丢失” |
| 阈值移动       | 调整分类决策阈值（以对率回归为例）：<br>原始阈值是0.5，调整为<br>$\frac{m^+}{m^-}$（<br>$m^+$是少数类样本数，<br>$m^-$是多数类样本数），让决策边界向多数类偏移 | 不允许修改样本的场景（比如有数据隐私限制）     | 优点：不需要修改样本，只调整阈值，操作简单；<br>缺点：依赖样本比例的准确估计，估计不准会影响效果 | 阈值调整图：左栏是“原始阈值0.5（多数类预测多）”，右栏是“调整后阈值0.3（少数类预测多）”，旁注“阈值偏移能平衡类别预测结果” |

### ➡️ 跳转至下一部分  
完成本章总结与任务安排后，点击导航栏跳转至其他章节：  
**[第05章：线性模型 - 第6部分（导航栏）](chter06.md)**
