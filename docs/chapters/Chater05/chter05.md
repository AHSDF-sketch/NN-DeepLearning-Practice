# 第05章：线性模型 - 第5部分（含导航栏）
## 5.5 多分类策略与类别不平衡处理（对应讲稿P21-P25）  
### 核心内容1：多分类任务拆解法  
| 策略类型       | 具体内容                                                                 | 优缺点分析                          | 讲稿对应页码 | 图示文字解释（匹配讲稿逻辑）                          |
|----------------|--------------------------------------------------------------------------|----------------------------------|--------------|-------------------------------------------------------|
| 一对一（OvO）  | 把$N$类拆成$\frac{N(N-1)}{2}$个二分类任务（比如3类拆成“1v2”“1v3”“2v3”）；<br>每个任务训练1个分类器，预测时用“投票制”——得票最多的类别就是最终结果 | 优点：单个分类器只需要用2类样本训练，训练速度快；<br>缺点：分类器数量多（$N=10$时要45个），存储开销和测试时间成本高 | P21          | 拆解示意图：左栏是“3类样本（1、2、3）”，中栏是“3个分类器（1v2、1v3、2v3）”，右栏是“投票结果（比如1得2票，预测为1）”，旁注“分类器多，但训练快” |
| 一对多（OvR）  | 把$N$类拆成$N$个二分类任务（比如3类拆成“1v其他”“2v其他”“3v其他”）；<br>每个任务训练1个分类器，预测时选“正例概率最高”的类别作为最终结果 | 优点：分类器数量少（只有$N$个），存储和测试成本低；<br>缺点：单个分类器需要用全量样本训练，训练慢；存在样本不平衡（“其他类”样本多） | P21          | 拆解示意图：左栏是“3类样本”，中栏是“3个分类器（1v其他、2v其他、3v其他）”，右栏是“概率结果（比如2的正例概率0.8最高，预测为2）”，旁注“分类器少，但训练慢” |
| 性能对比       | 多数情况下，两种策略的预测精度相近；<br>样本均衡时，选OvO或OvR都可以；<br>样本不平衡时，OvO更优（避免“其他类”样本过多导致的偏差） | 实际应用中，要根据“训练时间”和“存储成本”权衡，优先按数据特点选择 | P21          | 性能对比图：横轴标注“样本量”，纵轴标注“测试精度”，OvO和OvR的曲线重合，旁注“多数场景下精度一样，按工程成本决定” |

### 核心内容2：类别不平衡处理（样本比例差异大）  
| 处理方法       | 具体技术与逻辑                                                           | 适用场景                          | 优缺点分析                          | 讲稿对应页码 | 图示文字解释（匹配讲稿逻辑）                          |
|----------------|--------------------------------------------------------------------------|----------------------------------|----------------------------------|--------------|-------------------------------------------------------|
| 过采样         | 增加少数类样本数量，让类别比例平衡：<br>1. 简单复制：直接复制少数类样本（容易导致模型过拟合）；<br>2. SMOTE（合成少数类过采样技术）：在少数类样本的最近邻之间合成新样本（比如样本$A$和最近邻$B$之间，生成$A + \alpha(B - A)$，$\alpha$是0到1之间的数） | 少数类样本少且信息重要的场景（比如医疗罕见病检测、金融欺诈识别） | 优点：不会丢失信息，能提高少数类的识别率；<br>缺点：简单复制易过拟合，SMOTE的计算成本高 | P22-P23      | SMOTE示意图：左栏是“原始样本（少数类3个）”，右栏是“SMOTE后样本（少数类8个，含合成样本）”，旁注“合成新样本能减少过拟合风险” |
| 欠采样         | 减少多数类样本数量，让类别比例平衡：<br>1. 随机欠采样：随机删除多数类样本（容易丢失关键信息）；<br>2. NearMiss：删除与少数类样本距离远的多数类样本（保留相关样本，减少信息丢失）；<br>3. 聚类欠采样：对多数类做聚类，每个聚类选代表性样本（降低信息丢失，但计算复杂） | 多数类样本多且计算资源有限的场景（比如大规模数据集分类） | 优点：降低计算成本，避免模型对多数类过拟合；<br>缺点：随机欠采样容易丢失关键信息 | P24          | NearMiss示意图：左栏是“原始多数类（10个样本）”，右栏是“NearMiss后（5个样本，都靠近少数类）”，旁注“保留关键样本，减少信息丢失” |
| 阈值移动       | 调整分类决策阈值（以对率回归为例）：<br>原始阈值是0.5，调整为$\frac{m^+}{m^-}$（$m^+$是少数类样本数，$m^-$是多数类样本数），让决策边界向多数类偏移 | 不允许修改样本的场景（比如有数据隐私限制）     | 优点：不需要修改样本，只调整阈值，操作简单；<br>缺点：依赖样本比例的准确估计，估计不准会影响效果 | P22          | 阈值调整图：左栏是“原始阈值0.5（多数类预测多）”，右栏是“调整后阈值0.3（少数类预测多）”，旁注“阈值偏移能平衡类别预测结果” |

## 章节导航汇总（适配GitHub自主学习平台）  
- **返回项目首页**：[神经网络与深度学习自主学习平台](../../../../README.md)（路径可根据仓库实际目录调整，比如首页在`docs/README.md`，就改为`../../../README.md`）  
- **回顾第04章内容**：[第04章：损失函数 - 第1部分](../Chapter04/chapter04_part1.md)  
- **回顾本章各部分**：  
  - [第1部分：线性模型基础](chapter05_part1.md)  
  - [第2部分：线性回归求解](chapter05_part2.md)  
  - [第3部分：广义线性模型与对率回归](chapter05_part3.md)  
  - [第4部分：线性判别分析（LDA）](chapter05_part4.md)  
- **预告第06章内容**：下章聚焦“神经网络基础结构”（从线性模型过渡到非线性模型，讲解感知机、多层神经网络的构建与训练），点击进入：[第06章：神经网络基础 - 第1部分](../Chapter06/chapter06_part1.md)  

## 学习提示  
1. **公式核心**：重点牢记线性模型定义（$f(x) = w_1x_1 + ... + w_dx_d + b$）、单变量回归闭式解、对率函数（$g(z) = \frac{1}{1 + e^{-z}}$），避免符号混淆；  
2. **任务适配**：线性回归对应回归任务、对率回归对应分类任务、LDA对应“降维+分类”任务，要明确不同模型的适用场景；  
3. **工程细节**：多元回归中$X^T X$不满秩的正则化处理、LDA中$S_w$的奇异值分解、类别不平衡的SMOTE/NearMiss方法，是解决实际问题的关键，建议结合讲稿案例理解。
