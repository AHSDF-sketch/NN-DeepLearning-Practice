# 第07章：图卷积网络概述 - 第2部分
## 7.2 图深度学习与图数据特征
### 核心内容：深度编码器、网络目标与图数据关键特性  
| 核心要点       | 具体内容                                                                 | 图示文字解释                |
|----------------|--------------------------------------------------------------------------|-------------------------------------------------------|
| 深度图编码器的必要性 | 由于浅层嵌入泛化差、无非线性表达等局限，引入基于图神经网络的“深度编码器”，可自动学习节点复杂特征，适配动态图、新节点场景 | <img width="1348" height="738" alt="image" src="https://github.com/user-attachments/assets/1e5de447-cb77-4a03-ab06-a500adcfd027" />图深度学习与图数据特征”模块下“方法对比图”：左“浅层嵌入（嵌入查找表，标注‘泛化差’）”→右“深度编码器（图神经网络，标注‘自动学习特征’）”，旁注“深度方法解决浅层嵌入短板” |
| 图深度学习的核心目标 | 1. 节点分类：预测节点类型（如疾病图中“疾病节点”“症状节点”分类）；<br>2. 链路预测：判断两个节点是否存在关联（如药物-蛋白质是否相互作用）；<br>3. 社区检测：识别密集相连的节点簇（如社交网络中的兴趣小组）；<br>4. 网络相似性：计算两个（子）图的相似度（如两个分子图的结构相似性） |<img width="970" height="688" alt="image" src="https://github.com/user-attachments/assets/0905a4bb-72dd-4988-9530-0296f4a89e1b" /> |
| 传统深度学习的适配问题 | 图数据与图像、文本结构差异大，导致传统CNN/RNN无法直接复用：<br>1. 无固定“局部性”“滑动窗口”（图像有像素网格，图无固定局部定义）；<br>2. 置换不变性（节点无标准排序，打乱节点顺序不影响图结构） |<img width="1339" height="693" alt="image" src="https://github.com/user-attachments/assets/b71076d0-1f9f-4b21-b3ce-0f9a9e939354" />|
| 图数据的关键特性（不变性与等变性） | 1. 置换不变性：对节点重新排序后，图的核心结构与输出结果不变（如社交网络打乱用户编号，好友关系不变）；<br>2. 置换等变性：节点排序变化时，模型输出的结构与节点排序变化保持一致（如节点编号打乱，嵌入向量的相对关系不变） | <img width="1439" height="804" alt="image" src="https://github.com/user-attachments/assets/6411ec3e-8728-4426-ab5a-02511743e4a5" />|
| 图神经网络的核心特性 | 由多个“置换等变/置换不变函数”组成，天然适配图数据的结构特性；<br>对比：MLP等传统模型无此特性，处理图时易失效 | <img width="1244" height="820" alt="image" src="https://github.com/user-attachments/assets/112d580a-57bf-4b3c-8de6-dc8f670dc033" />|

> 作用：明确图深度学习的目标与图数据的独特特性，解释图卷积网络的设计初衷，为后续核心原理铺垫。  

### ➡️ 跳转至下一部分  
掌握图数据特征后，点击学习图卷积网络的核心原理：  
**[第07章：图卷积网络概述 - 第3部分](chter03.md)**
