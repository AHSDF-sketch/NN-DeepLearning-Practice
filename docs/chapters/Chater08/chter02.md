# 第08章：注意力机制 - 第2部分
## 8.2 注意力机制的计算（对应PPT“二.注意力机制的计算”模块）  
### 核心内容：三大核心概念与三阶段计算流程  
| 核心要点       | 具体内容                                                                 | 图示文字解释                     |
|----------------|--------------------------------------------------------------------------|-------------------------------------------------------|
| 三大核心概念（Query/Key/Value） | 1. Query（查询）：主观需求的特征向量（如“寻找人工智能书籍”的问题）；<br>2. Key（键）：被比对的物体突出特征向量（如书籍的标题、索引）；<br>3. Value（值）：物体本身的特征向量（如书籍的具体内容），通常与Key成对出现 | <img width="1477" height="895" alt="image" src="https://github.com/user-attachments/assets/f75f4baa-5fff-4e78-9d87-c79ed1afcdb2" />|
| 通俗举例理解   | 图书馆找书场景：<br> - Query：你的问题“有哪些关于人工智能的书？”；<br> - Key：每本书的标题/索引；<br> - Value：匹配书籍的具体内容；<br> - 逻辑：用Query比对所有Key，找到匹配项后返回对应Value |<img width="1423" height="486" alt="image" src="https://github.com/user-attachments/assets/a1e0491e-a86d-4314-8998-254cead84298" /> |
| 三阶段计算流程 | 阶段1：计算相关性——用点积、余弦相似度等方法，求Query与每个Key的匹配程度，得到注意力得分（s₁、s₂...sₙ）；<br>阶段2：权重归一化——得分缩放（除以特征维度平方根）后输入Softmax，转化为权重之和为1的概率分布（a₁、a₂...aₙ）；<br>阶段3：加权求和——将权重应用到对应Value上，加权求和得到最终Attention输出 | <img width="1446" height="857" alt="image" src="https://github.com/user-attachments/assets/47610130-01fe-4fad-9320-16a5bca63963" />|

> 作用：拆解注意力机制的核心组件与计算逻辑，通过通俗例子降低理解难度，明确“匹配-归一化-融合”的核心流程。  

### ➡️ 跳转至下一部分  
掌握计算流程后，点击学习注意力机制的核心类型与应用：  
**[第08章：注意力机制 - 第3部分](chter03.md)**
