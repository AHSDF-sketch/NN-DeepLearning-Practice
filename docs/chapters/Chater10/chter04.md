# 第10章：持续学习 - 第4部分
## 10.7 解决策略四：模型扩展
### 核心内容：核心逻辑与典型方法（PNN+Expert Gate）  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 核心逻辑               | 通过“扩展网络结构”容纳新任务知识——为每个新任务新增专属模块，旧模块参数固定不变；核心思想：“新知识存新结构，旧结构不动” | <img width="1700" height="800" alt="模型扩展逻辑图" src="https://placeholder.com/cl_expand_reg" /> <br> 图注：左栏“旧任务模块（参数固定）”，右栏“新任务新增模块（参数可训）”，箭头标注“新模块复用旧模块特征，不覆盖旧参数” |
| 典型方法1：PNN（渐进神经网络） | 1. **步骤**：<br>   - 任务1：构建网络列1，训练后固定参数；<br>   - 任务2：构建网络列2，新增隐藏层，将列1每层输出降维后作为列2额外输入；<br>   - 任务n：构建列n，复用前n-1列特征；<br>2. **优势**：无参数覆盖，旧任务性能100%保留 | <img width="1700" height="800" alt="PNN结构示意图" src="https://placeholder.com/cl_pnn" /> <br> 图注：列1（任务1）、列2（任务2）、列n（任务n），列间标注“侧向连接（降维输入）”，旁注“旧列固定，新列可训” |
| 典型方法2：Expert Gate（专家门） | 1. **步骤**：<br>   - 存储：保存所有旧任务“专家模型”（Expert 1~k）；<br>   - 输入：提取输入特征，通过Gate匹配相似度最高的专家模型；<br>   - 新类别：若输入为全新类，训练新专家模型并存储；<br>2. **优势**：适配“类别增量”任务，可解释性强 | <img width="1700" height="800" alt="Expert Gate示意图" src="https://placeholder.com/cl_expert_gate" /> <br> 图注：输入→特征提取→Gate匹配→调用对应Expert模型，旁注“新类别→新增Expert” |
| 其他方法               | 1. DEN（动态可扩展网络）：按需动态新增神经元，而非整层；<br>2. PL（渐进学习）：逐步扩展模型容量，适配任务复杂度增长 | <img width="1700" height="800" alt="扩展方法对比图" src="https://placeholder.com/cl_expand_other" /> <br> 图注：对比PNN、Expert Gate、DEN的“模型容量-任务数量”曲线 |

> 作用：掌握模型扩展通过“结构新增”解决遗忘的逻辑，理解PNN与Expert Gate的适用场景差异。


## 10.8 本章总结
### 核心内容：关键知识点与重点掌握模块  
| 模块分类               | 核心知识点                                                                 | 掌握要求                                                                 |
|------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 基础概念               | 1. 持续学习定义（可塑性+稳定性）；<br>2. 与迁移学习的差异；<br>3. 灾难性遗忘的定义与成因 | 理解记忆，能区分概念差异                                                 |
| 四大解决策略           | 1. **权重正则化**：EWC的参数重要性评估与正则项设计；<br>2. **梯度正则化**：GEM的梯度约束逻辑与步骤；<br>3. **经验重放**：生成式重放的模型构成与数据混合逻辑；<br>4. **模型扩展**：PNN的侧向连接与Expert Gate的匹配机制 | 重点掌握，能分析不同策略的“优势-劣势-适用场景”                           |
| 策略对比与选择         | 1. 参数约束类（权重/梯度正则化）：内存低，但适用任务有限；<br>2. 数据复用类（经验重放）：适配广，但依赖数据质量；<br>3. 结构扩展类（模型扩展）：无遗忘，但模型容量增长快 | 能根据任务场景（如内存、任务类型）选择合适策略                           |

> 作用：梳理本章核心脉络，明确重点掌握内容，帮助建立“问题-策略-选择”的完整知识框架。


## 本章核心考点提示
1. 简答题：灾难性遗忘的成因与至少两种解决策略的原理；  
2. 对比题：持续学习与迁移学习的核心差异；  
3. 案例分析题：给定“机器人连续学技能”场景，选择合适的持续学习策略并说明理由；  
4. 计算题（选考）：基于EWC损失函数，计算参数更新时的正则项惩罚值。
