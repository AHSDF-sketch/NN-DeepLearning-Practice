# 第10章：持续学习 - 第4部分
## 10.7 解决策略四：模型扩展
### 核心内容：核心逻辑与典型方法（PNN+Expert Gate）  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 核心逻辑               | 通过“扩展网络结构”容纳新任务知识——为每个新任务新增专属模块，旧模块参数固定不变；核心思想：“新知识存新结构，旧结构不动” | <img width="1767" height="906" alt="image" src="https://github.com/user-attachments/assets/fda58e3a-810b-4430-9355-7f9697444fc8" />|
| 典型方法1：PNN（渐进神经网络） | 1. **步骤**：<br>   - 任务1：构建网络列1，训练后固定参数；<br>   - 任务2：构建网络列2，新增隐藏层，将列1每层输出降维后作为列2额外输入；<br>   - 任务n：构建列n，复用前n-1列特征；<br>2. **优势**：无参数覆盖，旧任务性能100%保留 |<img width="1758" height="897" alt="image" src="https://github.com/user-attachments/assets/754dd478-ebbd-4f14-9195-8a5a3db2d8db" />|
| 典型方法2：Expert Gate（专家门） | 1. **步骤**：<br>   - 存储：保存所有旧任务“专家模型”（Expert 1~k）；<br>   - 输入：提取输入特征，通过Gate匹配相似度最高的专家模型；<br>   - 新类别：若输入为全新类，训练新专家模型并存储；<br>2. **优势**：适配“类别增量”任务，可解释性强 |<img width="1724" height="897" alt="image" src="https://github.com/user-attachments/assets/95576e08-30d8-4cb9-9c4c-22f2cc0c32a6" />|
| 其他方法               | 1. DEN（动态可扩展网络）：按需动态新增神经元，而非整层；<br>2. PL（渐进学习）：逐步扩展模型容量，适配任务复杂度增长 | <img width="1440" height="481" alt="image" src="https://github.com/user-attachments/assets/36d87eb3-e06f-4e28-834e-b8811d995fdf" /> |

> 作用：掌握模型扩展通过“结构新增”解决遗忘的逻辑，理解PNN与Expert Gate的适用场景差异。


## 10.8 本章总结
### 核心内容：关键知识点与重点掌握模块  
| 模块分类               | 核心知识点                                                                 | 掌握要求                                                                 |
|------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 基础概念               | 1. 持续学习定义（可塑性+稳定性）；<br>2. 与迁移学习的差异；<br>3. 灾难性遗忘的定义与成因 | 理解记忆，能区分概念差异                                                 |
| 四大解决策略           | 1. **权重正则化**：EWC的参数重要性评估与正则项设计；<br>2. **梯度正则化**：GEM的梯度约束逻辑与步骤；<br>3. **经验重放**：生成式重放的模型构成与数据混合逻辑；<br>4. **模型扩展**：PNN的侧向连接与Expert Gate的匹配机制 | 重点掌握，能分析不同策略的“优势-劣势-适用场景”                           |
| 策略对比与选择         | 1. 参数约束类（权重/梯度正则化）：内存低，但适用任务有限；<br>2. 数据复用类（经验重放）：适配广，但依赖数据质量；<br>3. 结构扩展类（模型扩展）：无遗忘，但模型容量增长快 | 能根据任务场景（如内存、任务类型）选择合适策略                           |

> 作用：梳理本章核心脉络，明确重点掌握内容，帮助建立“问题-策略-选择”的完整知识框架。


## 本章核心考点提示
1. 简答题：灾难性遗忘的成因与至少两种解决策略的原理；  
2. 对比题：持续学习与迁移学习的核心差异；  
3. 案例分析题：给定“机器人连续学技能”场景，选择合适的持续学习策略并说明理由；  
4. 计算题（选考）：基于EWC损失函数，计算参数更新时的正则项惩罚值。
### ➡️ 跳转至下一部分  
完成本章总结与任务安排后，点击导航栏跳转至其他章节：  
**[第10章：持续学习 - 第5部分（导航栏）](chter05.md)**
