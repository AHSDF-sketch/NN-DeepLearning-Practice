# 第10章：持续学习 - 第3部分
## 10.5 解决策略二：梯度正则化
### 核心内容：核心逻辑与典型方法（GEM）  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 核心逻辑               | 通过“存储旧任务梯度信息”，约束新任务梯度更新方向——确保新梯度不增加旧任务损失，同时贴近原始新梯度（保证新任务效果）；核心思想：“新梯度不与旧梯度冲突” | <img width="1768" height="901" alt="image" src="https://github.com/user-attachments/assets/df755653-be71-411f-b018-c6ea0b31cdd7" />|
| 典型方法：GEM（梯度情景记忆） | 1. **步骤**：<br>   - 存储：为旧任务保存“代表性数据子集”（情景记忆）；<br>   - 计算：新任务梯度g，与旧任务梯度gₖ的内积；<br>   - 修正：若g·gₖ<0，修正g为g'（满足内积≥0，且贴近g）；<br>   - 更新：用g'更新参数；<br>2. **优势**：无需评估参数重要性，适配动态任务流 |<img width="1760" height="899" alt="image" src="https://github.com/user-attachments/assets/54d65168-e51a-4cf9-bce8-682e91e1f9ca" /> |
| 其他方法               | 1. A-GEM（平均梯度情景记忆）：简化约束，仅要求与旧梯度平均方向一致；<br>2. OGD（正交梯度下降）：要求新梯度与旧梯度正交；<br>3. ε-SOFT-GEM：允许内积略小于0（≤ε），平衡灵活性 |<img width="1748" height="717" alt="image" src="https://github.com/user-attachments/assets/24ecd98f-0c29-4887-b9e1-421ba1d958e2" /> |

> 作用：理解梯度正则化通过“方向约束”解决遗忘的逻辑，掌握GEM的核心步骤与适用场景。


## 10.6 解决策略三：经验重放
### 核心内容：核心逻辑与典型方法（生成式重放）  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 核心逻辑               | 借鉴生物“记忆回放”机制，通过“存储/生成旧任务数据”，与新任务数据混合训练，让模型“回顾”旧知识；核心思想：“用数据重放替代参数保护” | 经验重放策略通过存储或生成过去任务参数加入到当前任务一起训练而达到回顾过去知识来防止遗忘。经验重放策略中比较常见的是生成式重播；如图所示，模型中包含生成模型和分类模型，通过生成模型生成过去任务的模拟参数，再加入到当前任务中一起训练，来防止遗忘产生。|
| 典型方法：生成式重放   | 1. **系统构成**：生成模型G（如GAN、VAE）+ 分类模型M；<br>2. **步骤**：<br>   - 旧任务后：训练G生成旧任务模拟数据（如“模拟猫图像”）；<br>   - 新任务时：采样G的模拟数据（xᵒˡᵈ,yᵒˡᵈ），与新数据（xⁿᵉʷ,yⁿᵉʷ）混合；<br>   - 训练：用混合数据优化M；<br>3. **优势**：内存高效（无需存真实旧数据） |<img width="1661" height="893" alt="image" src="https://github.com/user-attachments/assets/d3f4f68d-de45-4488-8dcb-4a22f14efa2f" /> |
| 其他方法               | 1. 自生成长期经验重放（SLER）：分级存储旧数据，优先重放关键数据；<br>2. 确定性经验重放：直接存储旧数据子集，不依赖生成模型（适用于小数据场景） | <img width="1740" height="604" alt="image" src="https://github.com/user-attachments/assets/17ab08f1-5f3f-4853-a9fc-842833b69dc1" />|

> 作用：掌握经验重放通过“数据复用”解决遗忘的逻辑，理解生成式重放的内存优势与适用场景。


### ➡️ 跳转至下一部分  
**[第10章：持续学习 - 第4部分](chapter10_part4.md)**
