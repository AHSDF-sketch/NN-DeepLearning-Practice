# 第10章：持续学习 - 第2部分
## 10.3 持续学习的核心挑战：灾难性遗忘
### 核心内容：定义、成因与策略分类  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 灾难性遗忘定义         | 深度神经网络的固有缺陷：学习新任务时，因内存限制、关键参数被覆盖，导致旧任务性能快速下降甚至完全遗忘的现象；<br>例：“识猫”准确率98.5%→学“识狗”后降至45%以下，无法区分猫与其他动物 | <img width="1747" height="908" alt="image" src="https://github.com/user-attachments/assets/166d2190-0236-4747-83bb-6326c2003e77" />|
| 本质成因               | 1. **参数覆盖**：旧任务关键参数（如“识猫”轮廓权重）与新任务参数（如“识狗”耳朵权重）重叠，新训练覆盖旧参数；<br>2. **全局影响**：单个神经元参数变化影响整个网络特征映射；<br>3. **内存限制**：无法存储所有旧任务数据，无法全任务重训 |<img width="1213" height="569" alt="image" src="https://github.com/user-attachments/assets/79e345e6-b48f-4d5a-8025-fbca24a0733d" /> |
| 解决策略分类           | 四大类：<br>1. 权重正则化：限制关键参数更新；<br>2. 梯度正则化：约束新任务梯度方向；<br>3. 经验重放：复用旧任务数据训练；<br>4. 模型扩展：新增结构存新知识 | <img width="1823" height="912" alt="image" src="https://github.com/user-attachments/assets/c20607a1-7e57-4509-88db-b9d1306eb791" />|

> 作用：剖析持续学习的核心障碍，明确问题根源与解决思路框架。


## 10.4 解决策略一：权重正则化
### 核心内容：核心逻辑与典型方法（EWC）  
| 核心要点               | 具体内容                                                                 | 图示文字解释                                                                 |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 核心逻辑               | 通过“评估参数对旧任务的重要性”，在新任务损失函数中加入正则项，限制重要参数的更新幅度；核心思想：“重要参数少动，次要参数微调” |<img width="1818" height="916" alt="image" src="https://github.com/user-attachments/assets/d725297a-8724-4738-8f6c-13d00c19060b" />|
| 典型方法：EWC（弹性权重合并） | 1. **步骤**：<br>   - 旧任务后：计算参数重要性权重ωᵢ（Hessian矩阵评估）；<br>   - 新任务时：损失函数加入正则项：<br>L_EWC = L_new + λ×Σ[ωᵢ×(θᵢ - θᵢ_old)²]<br> （其中L_new为新任务损失，λ为正则化系数，θᵢ_old为旧任务参数）；<br>   - 优化：确保重要参数（ωᵢ大）接近旧值θᵢᵒˡᵈ；<br>2. **效果**：旧任务遗忘率降低60%+ |<img width="1687" height="913" alt="image" src="https://github.com/user-attachments/assets/d412b26e-f797-4fb3-b399-6938822ad610" />|
| 其他方法               | 1. 智能突触：跟踪参数在旧任务的“贡献度”，替代Hessian权重；<br>2. 记忆感知突触：通过“参数变化对旧任务准确率的影响”定义重要性 | <img width="1777" height="806" alt="image" src="https://github.com/user-attachments/assets/91fc0cf7-07aa-499e-865c-e022792acc53" />|

> 作用：掌握权重正则化的核心逻辑，理解EWC的实现细节与优势，为后续策略对比铺垫。


### ➡️ 跳转至下一部分  
**[第10章：持续学习 - 第3部分](chter03.md)**
