# 第01章：导论 - 第6部分
## 1.4 神经网络与深度学习的发展历程  
### 核心内容：梳理领域关键突破，了解技术演进脉络  
按“技术里程碑”分为三大时代，关键时间线与意义如下：  

| 发展时代       | 时间       | 关键事件/模型                          | 核心意义                                  |
|----------------|------------|----------------------------------------|-------------------------------------------|
| 感知器时代     | 1943年     | 提出**M-P神经元模型**                  | 奠定人工神经元理论基础，开启领域研究        |
|                | 1949年     | 提出**赫布学习规则**                    | 确立“权重随神经元关联度调整”的学习逻辑      |
| BP算法时代     | 1986年     | 发表《通过反向传播误差来学习》          | 解决多层网络权重更新难题，推动神经网络实用化 |
|                | 1997年     | 提出**LSTM（长短期记忆网络）**          | 缓解RNN梯度消失问题，适配文本等时序数据    |
| 深度学习时代   | 2006年     | 提出**深度置信网络（DBN）**            | 突破深度网络训练瓶颈，正式开启深度学习时代  |
|                | 2011年     | 提出**ReLU激活函数**                   | 解决Sigmoid梯度消失，成为当前主流激活函数  |
|                | 2012年     | **AlexNet**获ImageNet冠军               | 验证深度学习在图像任务的优越性，普及CNN    |
|                | 2014年     | 提出**GAN（生成对抗网络）+ GoogLeNet**  | 开启生成式AI研究，优化网络效率            |
|                | 2015年     | 提出**ResNet（残差网络）**              | 解决网络退化问题，支持百层以上超深网络      |
|                | 2017年     | 提出**Transformer模型**                 | 基于自注意力机制，奠定大语言模型基础        |
|                | 2020年     | 发布**GPT-3**                          | 当时最大预训练语言模型，推动大模型发展    |
|                | 2021年     | 发布**AlphaFold 2**                    | 突破蛋白质结构预测，推动生物医学研究      |
|                | 2022年     | 发布**Stable Diffusion**                | 成为AI绘画标杆，拓展生成式AI应用场景      |  

### ➡️ 跳转至下一部分  
了解发展历程后，点击进入关键技术、应用领域与总结展望的学习：  
**[第01章：导论 - 第7部分](chter07.md)**
