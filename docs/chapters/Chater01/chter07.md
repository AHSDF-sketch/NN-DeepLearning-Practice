# 第01章：导论 - 第7部分
## 1.5 关键技术 + 1.6 应用领域 + 1.7 总结与展望  
### 1.5 关键技术（核心“零件”与“骨架”）  
- **基础组件技术**：  
  - 激活函数：ReLU（主流，计算快、缓解梯度消失）、Sigmoid（二分类概率输出）、Tanh（零均值）、Softmax（多分类概率分布，和为1）；  
  - 损失函数：  
    - MSE（均方误差）：适用于回归任务（如预测房价/温度），公式：$$\text{Loss} = \frac{1}{n} \times \sum_{i=1}^n (y_{\text{true},i} - y_{\text{pred},i})^2$$（$n$=样本数，$y_{\text{true}}$=真实值，$y_{\text{pred}}$=预测值）；  
    - 交叉熵：适用于分类任务（二分类/多分类），高效衡量概率分布差异，训练收敛更快；  
    - Triplet Loss（三元组损失）：适用于人脸识别/图像检索，拉近同类样本、拉远异类样本。  
  - 优化技术：梯度下降（参数更新核心算法）、Adam优化器（自适应学习率，提升效率）、Dropout（随机失活神经元，缓解过拟合）。  

- **架构创新技术**：  
  - CNN（图像专用）：卷积层（提局部特征，参数共享）、池化层（最大/平均池化，降维抗干扰）、全连接层（整合全局特征输出）；  
  - Transformer（文本/序列专用）：自注意力（抓全局依赖，无需时序顺序）、多头注意力（多维度关联学习）、位置编码（补时序信息，识别词序）。  


### 1.6 应用领域（技术落地场景）  
- **计算机视觉**：图像识别与分类（猫/狗、手写数字，准确率≥94%）、目标检测与追踪（定位物体+动态视频追踪）；  
- **自然语言处理**：文本理解（提关键词、判情感倾向）、文本生成（写文案、自动摘要、对话回复）。  


### 1.7 总结与展望  
- **核心总结**：  
  1. 神经网络是基础（神经元+层状架构），深度学习是进阶（多隐藏层+自动化特征提取）；  
  2. 算力（GPU/TPU）与大数据是领域快速发展的关键。  

- **未来展望**：  
  1. 技术：聚焦模型可解释性，破解深度学习“黑箱”；  
  2. 应用：渗透智能家居（语音控制）、智能交通（自动驾驶）、工业自动化（故障检测）。  


## 📝 自评小测验（检验学习效果）  
完成第01章学习后，点击自测关键概念：  
**[第01章导论 - 自评小测验](question01.md)** 

## 🚀 跳转至下一章（核心优化算法）  
完成自测后，学习神经网络训练核心技术：  
**[第02章：梯度下降](../Chapter02/chapter02_gradient_descent.md)**
