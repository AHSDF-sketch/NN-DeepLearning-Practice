# 习题四

## 一、单选题（4题）
### 1. 在卷积神经网络中，池化层的主要作用是？
- A、增加特征图的通道数
- B、减少特征图的空间尺寸
- C、引入非线性变换
- D、增加模型的深度
<details>
  <summary>查看答案与解析</summary>
  答案：B<br>
  解析：池化层通过下采样减少特征图的高度和宽度，从而降低计算复杂度和参数量。
</details>

### 2. 全局平均池化（Global Average Pooling）的主要优势是？
- A、保留更多的空间信息
- B、减少过拟合风险
- C、提高计算速度
- D、增强边缘检测能力
<details>
  <summary>查看答案与解析</summary>
  答案：B<br>
  解析：全局平均池化通过对每个特征图取平均值，大大减少参数数量，有效降低过拟合风险。
</details>

### 3. 在目标检测任务中，为什么需要避免过度使用池化操作？
- A、会降低模型精度
- B、会丢失精确的空间位置信息
- C、会增加计算成本
- D、会导致梯度消失
<details>
  <summary>查看答案与解析</summary>
  答案：B<br>
  解析：目标检测需要精确的物体位置信息，过度池化会损失空间细节，影响定位精度。
</details>

### 4. 下列哪种池化操作能够保留更多的纹理细节？
- A、2×2最大池化
- B、3×3最大池化
- C、2×2平均池化
- D、全局最大池化
<details>
  <summary>查看答案与解析</summary>
  答案：A<br>
  解析：较小的池化核（如2×2）能够保留更多的局部纹理细节，而较大的池化核会损失更多信息。
</details>


## 二、多选题（4题）
### 5. 池化操作在CNN中的主要好处包括？
- A、增加平移不变性
- B、扩大感受野
- C、减少内存消耗
- D、提高特征表达能力
- E、加速训练过程
<details>
  <summary>查看答案与解析</summary>
  答案：ABCE<br>
  解析：池化通过下采样提供平移不变性，扩大感受野，减少内存使用，并因参数减少而加速训练。
</details>

### 6. 关于可学习池化（Learnable Pooling）的描述正确的是？
- A、使用可学习参数替代固定操作
- B、能够自适应调整池化策略
- C、比传统池化计算更简单
- D、需要更多的训练数据
- E、在某些任务中性能更好
<details>
  <summary>查看答案与解析</summary>
  答案：ABE<br>
  解析：可学习池化通过参数化方式自适应学习池化函数，能更好地适应特定任务，但计算更复杂。
</details>

### 7. 空间金字塔池化（SPP）的主要特点是？
- A、处理任意尺寸的输入
- B、输出固定长度的特征向量
- C、使用多尺度池化核
- D、仅用于图像分类任务
- E、避免图像裁剪带来的信息损失
<details>
  <summary>查看答案与解析</summary>
  答案：ABCE<br>
  解析：SPP通过多尺度池化处理任意尺寸输入，生成固定维度的特征表示，广泛应用于各种视觉任务。
</details>

### 8. 重叠池化（Overlapping Pooling）与传统池化相比？
- A、池化窗口有重叠区域
- B、保留更多特征信息
- C、计算效率更高
- D、步长小于池化核尺寸
- E、在AlexNet中首次使用
<details>
  <summary>查看答案与解析</summary>
  答案：ABDE<br>
  解析：重叠池化的步长小于核尺寸，产生重叠感受野，保留更多信息，但计算量更大。
</details>


## 三、判断题（4题）
### 9. 池化操作可以完全被带步长的卷积层替代。
<details>
  <summary>查看答案与解析</summary>
  答案：正确<br>
  解析：带步长的卷积可以实现类似的下采样效果，且具有可学习的参数，在现代架构中常替代池化。
</details>

### 10. 平均池化比最大池化更适合用于梯度反向传播。
<details>
  <summary>查看答案与解析</summary>
  答案：错误<br>
  解析：两者在反向传播中都有明确的计算方式，没有绝对的优劣，取决于具体任务需求。
</details>

### 11. 反池化（Unpooling）操作通常用于语义分割任务。
<details>
  <summary>查看答案与解析</summary>
  答案：正确<br>
  解析：反池化在编码器-解码器结构中用于恢复空间分辨率，是语义分割中的常见操作。
</details>

### 12. 随机池化（Stochastic Pooling）完全随机选择池化值，不考虑数值大小。
<details>
  <summary>查看答案与解析</summary>
  答案：错误<br>
  解析：随机池化根据数值大小计算概率分布，按概率采样，数值大的元素被选中的概率更高。
</details>


## 四、简答题（4题）
### 13. 请解释最大池化在特征提取中的优势。
<details>
  <summary>查看答案与解析</summary>
  答案：最大池化通过选择局部最显著特征，增强特征表示的稀疏性，提高对平移和形变的鲁棒性，同时抑制噪声影响。<br>
  解析：这种"赢者通吃"的机制使网络关注最突出的特征，而非平均响应，有利于关键特征的保持。
</details>

### 14. 为什么在轻量化网络中常使用深度可分离卷积替代池化层？
<details>
  <summary>查看答案与解析</summary>
  答案：深度可分离卷积在减少参数和计算量的同时，通过步长实现下采样，并保留可学习能力，比固定池化更灵活高效。<br>
  解析：这种设计在MobileNet等轻量架构中取得良好效果，平衡了性能与效率。
</details>

### 15. 简述多尺度池化在计算机视觉中的应用价值。
<details>
  <summary>查看答案与解析</summary>
  答案：多尺度池化能同时捕获不同粒度的特征，增强模型对尺度变化的适应性，在目标检测、语义分割等任务中提升性能。<br>
  解析：通过并行使用不同大小的池化核，模型能够整合局部和全局信息，提高特征表达能力。
</details>

### 16. 池化操作在循环神经网络中有什么特殊应用？
<details>
  <summary>查看答案与解析</summary>
  答案：在RNN中，池化可用于时序下采样，降低序列长度，提取关键时间步特征，减少计算复杂度并缓解长程依赖问题。<br>
  解析：时序池化在语音处理、视频分析等长序列任务中特别有用。
</details>


## 五、填空题（4题）
### 17. 设输入特征图尺寸为H×W，池化核大小K，步长S，填充P，输出尺寸计算公式为______。
<details>
  <summary>查看答案与解析</summary>
  答案：⌊(H-K+2P)/S⌋+1 × ⌊(W-K+2P)/S⌋+1<br>
  解析：这与卷积层的输出尺寸计算方式相同，考虑核大小、步长和填充的影响。
</details>

### 18. 在最大池化中，反向传播时梯度只传递给前向传播中被选中的______。
<details>
  <summary>查看答案与解析</summary>
  答案：最大值位置<br>
  解析：最大池化的反向传播采用"赢者通吃"策略，只有前向传播中选中的最大值位置会接收梯度。
</details>

### 19. 全局平均池化将每个特征图缩减为______个值。
<details>
  <summary>查看答案与解析</summary>
  答案：1<br>
  解析：全局平均池化对每个通道的所有激活值取平均，生成通道数长度的特征向量。
</details>

### 20. 空间金字塔池化通常使用______种不同尺寸的池化核。
<details>
  <summary>查看答案与解析</summary>
  答案：多（通常3-4）<br>
  解析：SPP经典实现使用1×1、2×2、4×4等多个尺度的池化核来捕获多尺度特征。
</details>
